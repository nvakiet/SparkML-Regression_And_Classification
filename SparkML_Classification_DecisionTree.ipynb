{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-mL2KDv5XzPA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4d613c-de56-4cf3-c0da-5aa9bd6d9d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 32 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 52.1 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=4f5c937de6131eca8f8ade503d8eed771864f1ee2a15fdd9b9d127f582d93bd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IQl3BLVgoIkU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "import scipy\n",
        "\n",
        "spark = (SparkSession\n",
        "        .builder\n",
        "        .appName('lab 3 - Desicion tree')\n",
        "        .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_dxpQThYL_w"
      },
      "source": [
        "# IRIS DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xzYHAxQYYMPo"
      },
      "outputs": [],
      "source": [
        "df = spark.read.csv('Iris.csv', header = True, inferSchema = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-u6Cd7vkZmHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79443361-6908-4484-f97c-898b755857b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Do4wZpkMNi5"
      },
      "source": [
        "### PREPROCESSING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-DUoqLguRaJ"
      },
      "source": [
        "We are combining features into one single vector and renaming 'Species' to 'label'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JMpUUJQAMReu"
      },
      "outputs": [],
      "source": [
        "df = (StringIndexer(inputCol=\"Species\",outputCol=\"label\")\n",
        "          .fit(df)\n",
        "          .transform(VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\",\"PetalLengthCm\",\"PetalWidthCm\"],outputCol='features')\n",
        "                         .transform(df))\n",
        "          .drop('Id','SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species')\n",
        "          .distinct())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beSIxC6pue0t"
      },
      "source": [
        "The data after being pre-processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "QBgQmu3lA9X5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee4aab15-0ca9-464c-e427-1d380b122e6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[7.7,2.6,6.9,2.3]|  2.0|\n",
            "|[4.9,2.4,3.3,1.0]|  1.0|\n",
            "|[7.7,3.8,6.7,2.2]|  2.0|\n",
            "|[5.5,2.3,4.0,1.3]|  1.0|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|\n",
            "|[5.7,2.8,4.5,1.3]|  1.0|\n",
            "|[6.0,2.2,5.0,1.5]|  2.0|\n",
            "|[5.4,3.9,1.3,0.4]|  0.0|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|\n",
            "|[5.8,4.0,1.2,0.2]|  0.0|\n",
            "|[5.1,3.7,1.5,0.4]|  0.0|\n",
            "|[4.8,3.4,1.9,0.2]|  0.0|\n",
            "|[5.5,2.5,4.0,1.3]|  1.0|\n",
            "|[6.6,3.0,4.4,1.4]|  1.0|\n",
            "|[6.4,3.2,5.3,2.3]|  2.0|\n",
            "|[6.5,3.0,5.8,2.2]|  2.0|\n",
            "|[5.4,3.4,1.5,0.4]|  0.0|\n",
            "|[5.6,2.8,4.9,2.0]|  2.0|\n",
            "|[5.2,4.1,1.5,0.1]|  0.0|\n",
            "|[5.9,3.0,4.2,1.5]|  1.0|\n",
            "+-----------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTqBy8BJRqVp"
      },
      "source": [
        "### TRAINING MODEL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ev60ocmECWdH"
      },
      "source": [
        "We are creating a train function to reduce code repeating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "0lowp9J4B_td"
      },
      "outputs": [],
      "source": [
        "def train(df, classifier):\n",
        "  (train, test) = df.randomSplit([.7,.3])\n",
        "\n",
        "  model = classifier.fit(train)\n",
        "\n",
        "  pred = model.transform(test)\n",
        "\n",
        "  eval_accuracy = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"))\n",
        "  \n",
        "  eval_precision = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"))\n",
        "  \n",
        "  eval_recall = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\"))\n",
        "  \n",
        "  eval_f1 = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"))\n",
        "\n",
        "  accuracy = eval_accuracy.evaluate(pred)\n",
        "\n",
        "  precision =  eval_precision.evaluate(pred)\n",
        "\n",
        "  recall =  eval_recall.evaluate(pred)\n",
        "\n",
        "  f1 =  eval_f1.evaluate(pred)\n",
        "\n",
        "  print(f\"\"\"\n",
        "  Accuracy  = {accuracy}\n",
        "  Error     = {1-accuracy}\n",
        "  Precision = {precision}\n",
        "  Recall    = {recall}\n",
        "  F1        = {f1}\"\"\")\n",
        "\n",
        "  return model, pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EggxvwzHCjxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f820943-27c3-4fc6-e8c9-bf08805ec4a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Accuracy  = 0.9736842105263158\n",
            "  Error     = 0.02631578947368418\n",
            "  Precision = 0.9755639097744361\n",
            "  Recall    = 0.9736842105263157\n",
            "  F1        = 0.9733975461529641\n",
            "+----------+-----+-----------------+\n",
            "|prediction|label|         features|\n",
            "+----------+-----+-----------------+\n",
            "|       0.0|  0.0|[4.4,3.0,1.3,0.2]|\n",
            "|       0.0|  0.0|[4.6,3.6,1.0,0.2]|\n",
            "|       0.0|  0.0|[4.7,3.2,1.3,0.2]|\n",
            "|       0.0|  0.0|[4.8,3.1,1.6,0.2]|\n",
            "|       0.0|  0.0|[4.8,3.4,1.9,0.2]|\n",
            "|       0.0|  0.0|[5.0,3.2,1.2,0.2]|\n",
            "|       0.0|  0.0|[5.0,3.4,1.6,0.4]|\n",
            "|       0.0|  0.0|[5.0,3.5,1.3,0.3]|\n",
            "|       1.0|  1.0|[5.1,2.5,3.0,1.1]|\n",
            "|       0.0|  0.0|[5.1,3.3,1.7,0.5]|\n",
            "|       0.0|  0.0|[5.1,3.8,1.6,0.2]|\n",
            "|       1.0|  1.0|[5.2,2.7,3.9,1.4]|\n",
            "|       0.0|  0.0|[5.2,3.5,1.5,0.2]|\n",
            "|       0.0|  0.0|[5.2,4.1,1.5,0.1]|\n",
            "|       0.0|  0.0|[5.4,3.7,1.5,0.2]|\n",
            "|       0.0|  0.0|[5.4,3.9,1.7,0.4]|\n",
            "|       1.0|  1.0|[5.5,2.4,3.8,1.1]|\n",
            "|       0.0|  0.0|[5.5,3.5,1.3,0.2]|\n",
            "|       2.0|  2.0|[5.7,2.5,5.0,2.0]|\n",
            "|       1.0|  1.0|[5.7,3.0,4.2,1.2]|\n",
            "+----------+-----+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "_ , pred = train(df,dt)\n",
        "\n",
        "pred.select(\"prediction\", \"label\", \"features\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FyQWVI6YEz-"
      },
      "source": [
        "# BANK DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ptt0egwjX9Wn"
      },
      "outputs": [],
      "source": [
        "df = spark.read.option(\"delimiter\", \";\").csv('bank.csv', header = True, inferSchema = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "syuBzRSJYiqD",
        "outputId": "544b3de3-76de-4d34-cf36-4db78f1efe62",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|          job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "| 30|   unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
            "| 33|     services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
            "| 35|   management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
            "| 30|   management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n",
            "| 59|  blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n",
            "| 35|   management| single| tertiary|     no|    747|     no|  no|cellular| 23|  feb|     141|       2|  176|       3| failure| no|\n",
            "| 36|self-employed|married| tertiary|     no|    307|    yes|  no|cellular| 14|  may|     341|       1|  330|       2|   other| no|\n",
            "| 39|   technician|married|secondary|     no|    147|    yes|  no|cellular|  6|  may|     151|       2|   -1|       0| unknown| no|\n",
            "| 41| entrepreneur|married| tertiary|     no|    221|    yes|  no| unknown| 14|  may|      57|       2|   -1|       0| unknown| no|\n",
            "| 43|     services|married|  primary|     no|    -88|    yes| yes|cellular| 17|  apr|     313|       1|  147|       2| failure| no|\n",
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJFGOZBrFEEI"
      },
      "source": [
        "### PREPROCESSING\n",
        "We are doing as follow:\n",
        "* Dropping 'day' and 'month' as it does not make much senses in this scenario\n",
        "* Changing all nominal features into numeric type\n",
        "* Combining all features into one vector\n",
        "* Dropping everything, leaving 'label' and 'features' alone in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CAdVWWizwxBU"
      },
      "outputs": [],
      "source": [
        "df = df.drop('day','month')\n",
        "\n",
        "df = StringIndexer(inputCols=['job','marital','education','default','housing','loan','contact','poutcome','y'],\n",
        "                   outputCols=['job_','marital_','education_','default_','housing_','loan_','contact_','poutcome_','label']).fit(df).transform(df)\n",
        "\n",
        "df = df.drop('job','marital','education','default','housing','loan','contact','poutcome','y')\n",
        "\n",
        "df = VectorAssembler(inputCols=['campaign','balance','duration','pdays','previous','age','job_','marital_','education_','default_','housing_','loan_','contact_','poutcome_'],outputCol='features').transform(df)\n",
        "\n",
        "df = df.drop('campaign','balance','duration','pdays','previous','age','job_','marital_','education_','default_','housing_','loan_','contact_','poutcome_')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufWUQq1nn78u"
      },
      "source": [
        "The data after being pre-processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "UmSEudoisIDS",
        "outputId": "442379f6-be2e-4c85-bb14-e069c1d46ee0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------------------------------------------------+\n",
            "|label|features                                                         |\n",
            "+-----+-----------------------------------------------------------------+\n",
            "|0.0  |(14,[0,1,2,3,5,6,8,10],[1.0,1787.0,79.0,-1.0,30.0,8.0,2.0,1.0])  |\n",
            "|0.0  |[1.0,4789.0,220.0,339.0,4.0,33.0,4.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0]|\n",
            "|0.0  |[1.0,1350.0,185.0,330.0,1.0,35.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0]|\n",
            "|0.0  |(14,[0,1,2,3,5,8,11,12],[4.0,1476.0,199.0,-1.0,30.0,1.0,1.0,1.0])|\n",
            "|0.0  |(14,[0,2,3,5,6,12],[1.0,226.0,-1.0,59.0,1.0,1.0])                |\n",
            "+-----+-----------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(5,truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0pGw7a18ZlO1",
        "outputId": "675d3819-83f7-4488-8b68-68e9bf298723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Accuracy  = 0.8934010152284264\n",
            "  Error     = 0.10659898477157359\n",
            "  Precision = 0.8755953004677336\n",
            "  Recall    = 0.8934010152284264\n",
            "  F1        = 0.8810880774035685\n"
          ]
        }
      ],
      "source": [
        "model, _ = train(df,dt)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "DecisionTree .ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}