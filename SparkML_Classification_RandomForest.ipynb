{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KKAP_Spark_RandomForest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!tar xf spark-3.2.1-bin-hadoop3.2.tgz\n",
        "\n",
        "!pip install -q findspark\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mL2KDv5XzPA",
        "outputId": "f108a132-41f8-41ba-e9e3-92bd6a7f1677"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 36 kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9.3\n",
            "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 49.3 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=d99a1351aba922c5ea4baba0228f1accd841f9c7c996ebd8c95df224146293db\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IQl3BLVgoIkU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\"\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.feature import *\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "import scipy\n",
        "\n",
        "spark = (SparkSession\n",
        "        .builder\n",
        "        .appName('lab 3 - Desicion tree')\n",
        "        .getOrCreate()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IRIS DATASET"
      ],
      "metadata": {
        "id": "S_dxpQThYL_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('Iris.csv', header = True, inferSchema = True)"
      ],
      "metadata": {
        "id": "xzYHAxQYYMPo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-u6Cd7vkZmHs",
        "outputId": "a2b91ec7-73be-4e8e-8fc3-1de9fb1528f2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "| Id|SepalLengthCm|SepalWidthCm|PetalLengthCm|PetalWidthCm|    Species|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "|  1|          5.1|         3.5|          1.4|         0.2|Iris-setosa|\n",
            "|  2|          4.9|         3.0|          1.4|         0.2|Iris-setosa|\n",
            "|  3|          4.7|         3.2|          1.3|         0.2|Iris-setosa|\n",
            "|  4|          4.6|         3.1|          1.5|         0.2|Iris-setosa|\n",
            "|  5|          5.0|         3.6|          1.4|         0.2|Iris-setosa|\n",
            "+---+-------------+------------+-------------+------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREPROCESSING DATA"
      ],
      "metadata": {
        "id": "-Do4wZpkMNi5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are combining features into one single vector and renaming 'Species' to 'label'"
      ],
      "metadata": {
        "id": "V-DUoqLguRaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = (StringIndexer(inputCol=\"Species\",outputCol=\"label\")\n",
        "          .fit(df)\n",
        "          .transform(VectorAssembler(inputCols=[\"SepalLengthCm\", \"SepalWidthCm\",\"PetalLengthCm\",\"PetalWidthCm\"],outputCol='features')\n",
        "                         .transform(df))\n",
        "          .drop('Id','SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species')\n",
        "          .distinct())"
      ],
      "metadata": {
        "id": "JMpUUJQAMReu"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data after being pre-processed"
      ],
      "metadata": {
        "id": "beSIxC6pue0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBgQmu3lA9X5",
        "outputId": "299301d2-095e-4441-f6da-6ca43bccf477"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[7.7,2.6,6.9,2.3]|  2.0|\n",
            "|[4.9,2.4,3.3,1.0]|  1.0|\n",
            "|[7.7,3.8,6.7,2.2]|  2.0|\n",
            "|[5.5,2.3,4.0,1.3]|  1.0|\n",
            "|[5.4,3.7,1.5,0.2]|  0.0|\n",
            "|[5.7,2.8,4.5,1.3]|  1.0|\n",
            "|[6.0,2.2,5.0,1.5]|  2.0|\n",
            "|[5.4,3.9,1.3,0.4]|  0.0|\n",
            "|[6.7,3.3,5.7,2.5]|  2.0|\n",
            "|[5.8,4.0,1.2,0.2]|  0.0|\n",
            "|[5.1,3.7,1.5,0.4]|  0.0|\n",
            "|[4.8,3.4,1.9,0.2]|  0.0|\n",
            "|[5.5,2.5,4.0,1.3]|  1.0|\n",
            "|[6.6,3.0,4.4,1.4]|  1.0|\n",
            "|[6.4,3.2,5.3,2.3]|  2.0|\n",
            "|[6.5,3.0,5.8,2.2]|  2.0|\n",
            "|[5.4,3.4,1.5,0.4]|  0.0|\n",
            "|[5.6,2.8,4.9,2.0]|  2.0|\n",
            "|[5.2,4.1,1.5,0.1]|  0.0|\n",
            "|[5.9,3.0,4.2,1.5]|  1.0|\n",
            "+-----------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRAINING MODEL"
      ],
      "metadata": {
        "id": "iTqBy8BJRqVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are creating a train function to reduce code repeating"
      ],
      "metadata": {
        "id": "Ev60ocmECWdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(df, classifier):\n",
        "  (train, test) = df.randomSplit([.7,.3])\n",
        "\n",
        "  model = classifier.fit(train)\n",
        "\n",
        "  pred = model.transform(test)\n",
        "\n",
        "  eval_accuracy = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\"))\n",
        "  \n",
        "  eval_precision = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedPrecision\"))\n",
        "  \n",
        "  eval_recall = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\"))\n",
        "  \n",
        "  eval_f1 = (MulticlassClassificationEvaluator\n",
        "        (labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\"))\n",
        "\n",
        "  accuracy = eval_accuracy.evaluate(pred)\n",
        "\n",
        "  precision =  eval_precision.evaluate(pred)\n",
        "\n",
        "  recall =  eval_recall.evaluate(pred)\n",
        "\n",
        "  f1 =  eval_f1.evaluate(pred)\n",
        "\n",
        "  print(f\"\"\"\n",
        "  Accuracy  = {accuracy}\n",
        "  Error     = {1-accuracy}\n",
        "  Precision = {precision}\n",
        "  Recall    = {recall}\n",
        "  F1        = {f1}\"\"\")\n",
        "\n",
        "  return model, pred"
      ],
      "metadata": {
        "id": "0lowp9J4B_td"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "\n",
        "_ , pred = train(df,rf)\n",
        "\n",
        "pred.select(\"prediction\", \"label\", \"features\").show()"
      ],
      "metadata": {
        "id": "EggxvwzHCjxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60aa0abc-6422-4a51-8032-32548c0a1596"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Accuracy  = 0.9791666666666666\n",
            "  Error     = 0.02083333333333337\n",
            "  Precision = 0.9805555555555555\n",
            "  Recall    = 0.9791666666666667\n",
            "  F1        = 0.979244330537434\n",
            "+----------+-----+-----------------+\n",
            "|prediction|label|         features|\n",
            "+----------+-----+-----------------+\n",
            "|       0.0|  0.0|[4.6,3.2,1.4,0.2]|\n",
            "|       0.0|  0.0|[4.6,3.4,1.4,0.3]|\n",
            "|       0.0|  0.0|[4.8,3.4,1.6,0.2]|\n",
            "|       0.0|  0.0|[4.8,3.4,1.9,0.2]|\n",
            "|       0.0|  0.0|[4.9,3.0,1.4,0.2]|\n",
            "|       0.0|  0.0|[5.0,3.0,1.6,0.2]|\n",
            "|       0.0|  0.0|[5.0,3.4,1.5,0.2]|\n",
            "|       0.0|  0.0|[5.0,3.6,1.4,0.2]|\n",
            "|       1.0|  1.0|[5.1,2.5,3.0,1.1]|\n",
            "|       0.0|  0.0|[5.1,3.5,1.4,0.3]|\n",
            "|       0.0|  0.0|[5.2,3.4,1.4,0.2]|\n",
            "|       0.0|  0.0|[5.2,3.5,1.5,0.2]|\n",
            "|       0.0|  0.0|[5.4,3.4,1.5,0.4]|\n",
            "|       0.0|  0.0|[5.4,3.7,1.5,0.2]|\n",
            "|       1.0|  1.0|[5.5,2.3,4.0,1.3]|\n",
            "|       1.0|  1.0|[5.5,2.5,4.0,1.3]|\n",
            "|       0.0|  0.0|[5.5,4.2,1.4,0.2]|\n",
            "|       2.0|  2.0|[5.6,2.8,4.9,2.0]|\n",
            "|       1.0|  1.0|[5.6,2.9,3.6,1.3]|\n",
            "|       1.0|  1.0|[5.7,2.8,4.1,1.3]|\n",
            "+----------+-----+-----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BANK DATASET"
      ],
      "metadata": {
        "id": "6FyQWVI6YEz-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.option(\"delimiter\", \";\").csv('bank.csv', header = True, inferSchema = True)"
      ],
      "metadata": {
        "id": "ptt0egwjX9Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syuBzRSJYiqD",
        "outputId": "134410ce-c534-4664-91c7-5284586419f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|          job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "| 30|   unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
            "| 33|     services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
            "| 35|   management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
            "| 30|   management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n",
            "| 59|  blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n",
            "| 35|   management| single| tertiary|     no|    747|     no|  no|cellular| 23|  feb|     141|       2|  176|       3| failure| no|\n",
            "| 36|self-employed|married| tertiary|     no|    307|    yes|  no|cellular| 14|  may|     341|       1|  330|       2|   other| no|\n",
            "| 39|   technician|married|secondary|     no|    147|    yes|  no|cellular|  6|  may|     151|       2|   -1|       0| unknown| no|\n",
            "| 41| entrepreneur|married| tertiary|     no|    221|    yes|  no| unknown| 14|  may|      57|       2|   -1|       0| unknown| no|\n",
            "| 43|     services|married|  primary|     no|    -88|    yes| yes|cellular| 17|  apr|     313|       1|  147|       2| failure| no|\n",
            "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PREPROCESSING\n",
        "We are doing as follow:\n",
        "* Dropping 'day' and 'month' as it does not make much senses in this scenario\n",
        "* Changing all nominal features into numeric type\n",
        "* Combining all features into one vector\n",
        "* Dropping everything, leaving 'label' and 'features' alone in the dataset"
      ],
      "metadata": {
        "id": "hJFGOZBrFEEI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('day','month')\n",
        "\n",
        "df = StringIndexer(inputCols=['job','marital','education','default','housing','loan','contact','poutcome','y'],\n",
        "                   outputCols=['job_','marital_','education_','default_','housing_','loan_','contact_','poutcome_','label']).fit(df).transform(df)\n",
        "\n",
        "df = df.drop('job','marital','education','default','housing','loan','contact','poutcome','y')\n",
        "\n",
        "df = VectorAssembler(inputCols=['campaign','balance','duration','pdays','previous','age','job_','marital_','education_','default_','housing_','loan_','contact_','poutcome_'],outputCol='features').transform(df)\n",
        "\n",
        "df = df.drop('campaign','balance','duration','pdays','previous','age','job_','marital_','education_','default_','housing_','loan_','contact_','poutcome_')"
      ],
      "metadata": {
        "id": "CAdVWWizwxBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data after being pre-processed"
      ],
      "metadata": {
        "id": "ufWUQq1nn78u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5,truncate=False)"
      ],
      "metadata": {
        "id": "UmSEudoisIDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3ccbc75-b9b4-44f9-928b-360d9b023e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------------------------------------------------------------+\n",
            "|label|features                                                         |\n",
            "+-----+-----------------------------------------------------------------+\n",
            "|0.0  |(14,[0,1,2,3,5,6,8,10],[1.0,1787.0,79.0,-1.0,30.0,8.0,2.0,1.0])  |\n",
            "|0.0  |[1.0,4789.0,220.0,339.0,4.0,33.0,4.0,0.0,0.0,0.0,0.0,1.0,0.0,1.0]|\n",
            "|0.0  |[1.0,1350.0,185.0,330.0,1.0,35.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0]|\n",
            "|0.0  |(14,[0,1,2,3,5,8,11,12],[4.0,1476.0,199.0,-1.0,30.0,1.0,1.0,1.0])|\n",
            "|0.0  |(14,[0,2,3,5,6,12],[1.0,226.0,-1.0,59.0,1.0,1.0])                |\n",
            "+-----+-----------------------------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, _ = train(df,rf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pGw7a18ZlO1",
        "outputId": "7d266329-53b2-4bb8-b2b2-42e106cfbc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Accuracy  = 0.8766140602582496\n",
            "  Error     = 0.12338593974175038\n",
            "  Precision = 0.8475885663834014\n",
            "  Recall    = 0.8766140602582496\n",
            "  F1        = 0.8342757476017666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the accuracy are likely able to be improved, we will attempt to tweak a bit further\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7LBXpbqBBWGI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Removing Redundant features and using Cross-Validation\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "gBUdMGBoBnSH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sorting the importance of features by indices, judging from the model above"
      ],
      "metadata": {
        "id": "R7kFH2d2zjKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ImportanceIndices = sorted(range(14),key=model.featureImportances.__getitem__)\n",
        "ImportanceValues = sorted(model.featureImportances)\n",
        "\n",
        "print(ImportanceIndices)\n",
        "print(ImportanceValues)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHn9Qi0wsu84",
        "outputId": "12917c08-00dd-4a57-bb08-10be99ee64d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 9, 8, 0, 7, 12, 10, 6, 1, 5, 4, 3, 13, 2]\n",
            "[0.0014649061338201752, 0.008240646134561528, 0.011759270081439238, 0.012445646481029195, 0.014984466067493669, 0.021697027225567385, 0.03899294309758794, 0.0415219628246062, 0.05401590239463329, 0.05708783136310182, 0.059666559870715806, 0.06852779066806518, 0.18474537036686034, 0.42484967729051826]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We remove at most 4% least importance features, keeping 96% of the total"
      ],
      "metadata": {
        "id": "kPci2gRiHKJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colsToRemove = []\n",
        "dv = 0\n",
        "\n",
        "for i, v in zip(ImportanceIndices, ImportanceValues):\n",
        "  dv += v\n",
        "  if dv > 0.04: break\n",
        "  colsToRemove.append(i)\n",
        "\n",
        "print(colsToRemove)\n",
        "\n",
        "df = VectorSlicer(inputCol='features', outputCol=\"features_\", indices=[i for i in range(14) if i not in colsToRemove]).transform(df)\n",
        "\n",
        "df.show(1)\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_\")"
      ],
      "metadata": {
        "id": "ujolFqJiHhhO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21acb7f1-a5a4-415f-e9b7-6aa77c6a1e3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 9, 8, 0]\n",
            "+-----+--------------------+--------------------+\n",
            "|label|            features|           features_|\n",
            "+-----+--------------------+--------------------+\n",
            "|  0.0|(14,[0,1,2,3,5,6,...|(10,[0,1,2,4,5,7]...|\n",
            "+-----+--------------------+--------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we use cross validation technique to tune the model hyperparameters such as numTrees and maxDepth. Due to the nature of this dataset, we prioritize \"recall\" for the model evaluation. The validator will return the model with the best recall after running through 10 folds."
      ],
      "metadata": {
        "id": "YbZqKIzlp_NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "import numpy as np\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n",
        "pipeline = Pipeline(stages=[rf])\n",
        "\n",
        "paramGrid = ParamGridBuilder() \\\n",
        "    .addGrid(rf.numTrees, [int(x) for x in np.linspace(start = 10, stop = 50, num = 3)]) \\\n",
        "    .addGrid(rf.maxDepth, [int(x) for x in np.linspace(start = 5, stop = 25, num = 3)]) \\\n",
        "    .build()\n",
        "\n",
        "crossval = CrossValidator(estimator=pipeline,\n",
        "                      estimatorParamMaps=paramGrid,\n",
        "                      evaluator=MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"weightedRecall\"),\n",
        "                      numFolds=10)\n",
        "\n",
        "train(df, crossval)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llg1feaPOXff",
        "outputId": "9854d287-6095-403d-8756-200f499d87f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Accuracy  = 0.8920327624720774\n",
            "  Error     = 0.10796723752792259\n",
            "  Precision = 0.8738300275767517\n",
            "  Recall    = 0.8920327624720774\n",
            "  F1        = 0.8778286768070956\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(CrossValidatorModel_b0baab70487e,\n",
              " DataFrame[label: double, features: vector, features_: vector, rawPrediction: vector, probability: vector, prediction: double])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy after all did get 1.2% better!"
      ],
      "metadata": {
        "id": "xolxXOXWoBO0"
      }
    }
  ]
}